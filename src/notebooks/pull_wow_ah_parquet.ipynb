{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58c4720",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Config\nblizzard.api_client_id\n  Value error, API client ID must be provided [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error\nblizzard.api_client_secret\n  Value error, API client secret must be provided [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[32m      9\u001b[39m project_root = Path(os.getcwd()).parent.parent\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m CONFIG = \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_root\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig.toml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(CONFIG)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal/wow-analytics/src/config/loader.py:140\u001b[39m, in \u001b[36mload_config\u001b[39m\u001b[34m(config_path)\u001b[39m\n\u001b[32m    136\u001b[39m     toml_data = tomllib.load(f)\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Create config with TOML data as defaults\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Environment variables will automatically override via pydantic-settings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m config = \u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtoml_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal/wow-analytics/.venv/lib/python3.12/site-packages/pydantic_settings/main.py:194\u001b[39m, in \u001b[36mBaseSettings.__init__\u001b[39m\u001b[34m(__pydantic_self__, _case_sensitive, _nested_model_default_partial_update, _env_prefix, _env_file, _env_file_encoding, _env_ignore_empty, _env_nested_delimiter, _env_nested_max_split, _env_parse_none_str, _env_parse_enums, _cli_prog_name, _cli_parse_args, _cli_settings_source, _cli_parse_none_str, _cli_hide_none_type, _cli_avoid_json, _cli_enforce_required, _cli_use_class_docs_for_groups, _cli_exit_on_error, _cli_prefix, _cli_flag_prefix_char, _cli_implicit_flags, _cli_ignore_unknown_args, _cli_kebab_case, _cli_shortcuts, _secrets_dir, **values)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    165\u001b[39m     __pydantic_self__,\n\u001b[32m    166\u001b[39m     _case_sensitive: \u001b[38;5;28mbool\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m     **values: Any,\n\u001b[32m    193\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_settings_build_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_case_sensitive\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_case_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_nested_model_default_partial_update\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_nested_model_default_partial_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_file_encoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_file_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_ignore_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_ignore_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_nested_max_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_nested_max_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_parse_none_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_parse_none_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_parse_enums\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_parse_enums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_prog_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_prog_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_parse_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_parse_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_settings_source\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_settings_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_parse_none_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_parse_none_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_hide_none_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_hide_none_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_avoid_json\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_avoid_json\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_enforce_required\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_enforce_required\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_use_class_docs_for_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_use_class_docs_for_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_exit_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_exit_on_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_flag_prefix_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_flag_prefix_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_implicit_flags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_implicit_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_ignore_unknown_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_ignore_unknown_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_kebab_case\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_kebab_case\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_shortcuts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_shortcuts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_secrets_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_secrets_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal/wow-analytics/.venv/lib/python3.12/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 2 validation errors for Config\nblizzard.api_client_id\n  Value error, API client ID must be provided [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error\nblizzard.api_client_secret\n  Value error, API client secret must be provided [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Configuration & base setup #\n",
    "##############################\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from config.loader import load_config\n",
    "\n",
    "project_root = Path(os.getcwd()).parent.parent\n",
    "CONFIG = load_config(project_root / \"config.toml\")\n",
    "print(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import httpx\n",
    "from authlib.integrations.httpx_client import AsyncOAuth2Client\n",
    "\n",
    "class BlizzardAuctionHouseClient:\n",
    "    \"\"\"Client for fetching World of Warcraft Auction House data from Battle.net API\"\"\"\n",
    "\n",
    "    def __init__(self, client_id, client_secret, region=\"us\", locale=\"en_US\"):\n",
    "        \"\"\"\n",
    "        Initialize the client with OAuth credentials\n",
    "        \n",
    "        Args:\n",
    "            client_id: Your Battle.net API client ID\n",
    "            client_secret: Your Battle.net API client secret\n",
    "            region: API region ('us', 'eu', 'kr', 'tw', 'cn')\n",
    "        \"\"\"\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.region = region.lower()\n",
    "        \n",
    "        # Set region-specific endpoints\n",
    "        self.token_url = f'https://{self.region}.battle.net/oauth/token'\n",
    "        self.api_base = f'https://{self.region}.api.blizzard.com'\n",
    "\n",
    "        # Namespaces\n",
    "        self.namespace_static = f\"static-{self.region}\"\n",
    "        self.namespace_dynamic = f\"dynamic-{self.region}\"\n",
    "\n",
    "        # Locale\n",
    "        self.locale = locale\n",
    "\n",
    "        # HTTP default params\n",
    "        self.default_params = {'namespace': self.namespace_dynamic, 'locale': self.locale}\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        \"\"\"Async context manager entry\"\"\"\n",
    "        await self._authenticate()\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Async context manager exit\"\"\"\n",
    "        if self.client:\n",
    "            await self.client.aclose()\n",
    "    \n",
    "    async def _authenticate(self):\n",
    "        \"\"\"Authenticate and get access token using client credentials flow\"\"\"\n",
    "        try:\n",
    "            self.client = AsyncOAuth2Client(\n",
    "                client_id=self.client_id,\n",
    "                client_secret=self.client_secret,\n",
    "                token_endpoint=self.token_url\n",
    "            )\n",
    "            \n",
    "            self.token = await self.client.fetch_token(\n",
    "                self.token_url,\n",
    "                grant_type='client_credentials'\n",
    "            )\n",
    "            print(f\"Successfully authenticated. Token expires in {self.token.get('expires_in')} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Authentication failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def _ensure_valid_token(self):\n",
    "        \"\"\"Check if token is valid and refresh if necessary\"\"\"\n",
    "        if not self.token or self.token.get('expires_at', 0) <= time.time():\n",
    "            print(\"Token expired or missing, re-authenticating...\")\n",
    "            self._authenticate()\n",
    "\n",
    "    async def get_connected_realms_index(self):\n",
    "        \"\"\"\n",
    "        Get the connected realms index\n",
    "        \n",
    "        Returns:\n",
    "            List of realm IDs\n",
    "        \"\"\"\n",
    "        await self._ensure_valid_token()\n",
    "        \n",
    "        url = f\"{self.api_base}/data/wow/connected-realm/index\"\n",
    "        \n",
    "        response = await self.client.get(url, params=self.default_params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        realms_id = []\n",
    "        for realm in response.json().get('connected_realms', []):\n",
    "            href = realm.get('href', '')\n",
    "            realm_id = href.split('/')[-1].split('?')[0] if href else None\n",
    "            if realm_id and realm_id.isdigit():\n",
    "                realms_id.append(int(realm_id))\n",
    "\n",
    "        return realms_id\n",
    "    \n",
    "    async def get_connected_realm_details(self, connected_realm_id):\n",
    "        \"\"\"Get details for a specific connected realm\"\"\"\n",
    "        await self._ensure_valid_token()\n",
    "        \n",
    "        url = f\"{self.api_base}/data/wow/connected-realm/{connected_realm_id}\"\n",
    "        \n",
    "        response = await self.client.get(url, params=self.default_params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    async def get_auctions(self, connected_realm_id):\n",
    "        \"\"\"\n",
    "        Get auction house data for a specific connected realm\n",
    "        \n",
    "        Args:\n",
    "            connected_realm_id: The connected realm ID\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing auction house data\n",
    "        \"\"\"\n",
    "        await self._ensure_valid_token()\n",
    "        \n",
    "        url = f\"{self.api_base}/data/wow/connected-realm/{connected_realm_id}/auctions\"\n",
    "        \n",
    "        response = await self.client.get(url, params=self.default_params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    async def get_commodity_auctions(self):\n",
    "        \"\"\"\n",
    "        Get commodity auction house data (items that are region-wide)\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing commodity auction data\n",
    "        \"\"\"\n",
    "        await self._ensure_valid_token()\n",
    "        \n",
    "        url = f\"{self.api_base}/data/wow/auctions/commodities\"\n",
    "        \n",
    "        response = await self.client.get(url, params=self.default_params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    async def get_multiple_realm_auctions(self, connected_realm_ids, max_concurrent=5):\n",
    "        \"\"\"\n",
    "        Fetch auctions for multiple realms concurrently\n",
    "        \n",
    "        Args:\n",
    "            connected_realm_ids: List of connected realm IDs\n",
    "            max_concurrent: Maximum number of concurrent requests\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping realm_id to auction data\n",
    "        \"\"\"\n",
    "        semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        \n",
    "        async def fetch_with_semaphore(realm_id):\n",
    "            async with semaphore:\n",
    "                try:\n",
    "                    print(f\"Fetching auctions for realm {realm_id}...\")\n",
    "                    data = await self.get_auctions(realm_id)\n",
    "                    print(f\"Completed realm {realm_id}: {len(data.get('auctions', []))} auctions\")\n",
    "                    return realm_id, data\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching realm {realm_id}: {e}\")\n",
    "                    return realm_id, None\n",
    "        \n",
    "        tasks = [fetch_with_semaphore(realm_id) for realm_id in connected_realm_ids]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        return {realm_id: data for realm_id, data in results if data is not None}\n",
    "    \n",
    "    async def get_all_realm_details(self, realm_ids, max_concurrent=10):\n",
    "        \"\"\"\n",
    "        Fetch detailed information for multiple realms concurrently\n",
    "        \n",
    "        Args:\n",
    "            realm_ids: List of connected realm IDs\n",
    "            max_concurrent: Maximum number of concurrent requests\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping realm_id to realm details\n",
    "        \"\"\"\n",
    "        semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        \n",
    "        async def fetch_with_semaphore(realm_id):\n",
    "            async with semaphore:\n",
    "                try:\n",
    "                    return realm_id, await self.get_connected_realm_details(realm_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching realm {realm_id} details: {e}\")\n",
    "                    return realm_id, None\n",
    "        \n",
    "        tasks = [fetch_with_semaphore(realm_id) for realm_id in realm_ids]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        return {realm_id: data for realm_id, data in results if data is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46516397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "class ParquetWriter:\n",
    "    \"\"\"Handles writing Battle.net API data to Parquet format\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, region, compression='snappy'):\n",
    "        \"\"\"\n",
    "        Initialize the Parquet writer\n",
    "        \n",
    "        Args:\n",
    "            root_dir: Directory to save Parquet files\n",
    "            region: Name of the Blizzard region\n",
    "            compression: Compression algorithm ('snappy', 'gzip', 'brotli', 'zstd')\n",
    "        \n",
    "        Raises:\n",
    "            FileNotFoundError: If the root_dir does not exist\n",
    "            NotADirectoryError: If the root_dir is not a directory\n",
    "            PermissionError: If the root_dir is not writable\n",
    "        \"\"\"\n",
    "        self.region = region\n",
    "        self.root_dir = Path(root_dir)\n",
    "        \n",
    "        # Validate root_dir exists\n",
    "        if not self.root_dir.exists():\n",
    "            raise FileNotFoundError(f\"Root data directory does not exist: {self.root_dir}\")\n",
    "        \n",
    "        # Validate root_dir is a directory\n",
    "        if not self.root_dir.is_dir():\n",
    "            raise NotADirectoryError(f\"Root data path is not a directory: {self.root_dir}\")\n",
    "        \n",
    "        # Validate root_dir is writable\n",
    "        if not os.access(self.root_dir, os.W_OK):\n",
    "            raise PermissionError(f\"Root data directory is not writable: {self.root_dir}\")\n",
    "\n",
    "        self.data_dir = self.root_dir / self.region\n",
    "        self.data_dir.mkdir(mode=0o774, exist_ok=True)\n",
    "        \n",
    "        self.compression = compression\n",
    "    \n",
    "    def save_auctions_to_parquet(self, auction_data, filename, connected_realm_id=None):\n",
    "        \"\"\"\n",
    "        Save auction data to Parquet format with optimized schema\n",
    "        \n",
    "        Args:\n",
    "            auction_data: Raw auction data from API\n",
    "            filename: Output filename (can be Path or string)\n",
    "            connected_realm_id: Optional realm ID to include in data\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame of the saved data or None if no auctions\n",
    "        \"\"\"\n",
    "        auctions = auction_data.get('auctions', [])\n",
    "        \n",
    "        if not auctions:\n",
    "            print(\"No auctions to save\")\n",
    "            return None\n",
    "        \n",
    "        # Flatten the nested structure\n",
    "        flattened_auctions = []\n",
    "        timestamp = datetime.utcnow()\n",
    "        \n",
    "        for auction in auctions:\n",
    "            flat_auction = {\n",
    "                'fetch_timestamp': timestamp,\n",
    "                'auction_id': auction.get('id'),\n",
    "                'item_id': auction.get('item', {}).get('id'),\n",
    "                'quantity': auction.get('quantity', 1),\n",
    "                'unit_price': auction.get('unit_price'),\n",
    "                'buyout': auction.get('buyout'),\n",
    "                'time_left': auction.get('time_left'),\n",
    "            }\n",
    "            \n",
    "            # Add optional fields\n",
    "            if connected_realm_id:\n",
    "                flat_auction['connected_realm_id'] = connected_realm_id\n",
    "            \n",
    "            # Handle item bonuses\n",
    "            item = auction.get('item', {})\n",
    "            if 'bonus_lists' in item:\n",
    "                flat_auction['bonus_lists'] = ','.join(map(str, item['bonus_lists']))\n",
    "            \n",
    "            if 'modifiers' in item:\n",
    "                for mod in item['modifiers']:\n",
    "                    mod_type = mod.get('type')\n",
    "                    mod_value = mod.get('value')\n",
    "                    flat_auction[f'modifier_{mod_type}'] = mod_value\n",
    "            \n",
    "            # Handle bid (may not be present for all auctions)\n",
    "            if 'bid' in auction:\n",
    "                flat_auction['bid'] = auction['bid']\n",
    "            \n",
    "            flattened_auctions.append(flat_auction)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(flattened_auctions)\n",
    "        \n",
    "        # Optimize data types for better compression\n",
    "        df = self._optimize_auction_dtypes(df)\n",
    "        \n",
    "        # Ensure filename is a Path and save\n",
    "        filepath = self.data_dir / filename if not Path(filename).is_absolute() else Path(filename)\n",
    "        df.to_parquet(\n",
    "            filepath,\n",
    "            engine='pyarrow',\n",
    "            compression=self.compression,\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        file_size = filepath.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "        print(f\"Saved {len(df)} auctions to {filepath} ({file_size:.2f} MB)\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def save_connected_realms_to_parquet(self, realms_id, filename, realm_details=None):\n",
    "        \"\"\"\n",
    "        Save connected realms data to Parquet format\n",
    "        \n",
    "        Args:\n",
    "            realms_id: List of connected realm IDs\n",
    "            filename: Output filename (can be Path or string)\n",
    "            realm_details: Optional dictionary of realm_id -> detailed realm info\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame of the saved data or None if no realms\n",
    "        \"\"\"\n",
    "        \n",
    "        if not realms_id:\n",
    "            print(\"No connected realms to save\")\n",
    "            return None\n",
    "\n",
    "        # Parse detailed information\n",
    "        realm_list = []\n",
    "        for realm_id in realms_id:\n",
    "            detail = realm_details.get(realm_id)\n",
    "            \n",
    "            if detail:\n",
    "                realm_info = {\n",
    "                    'connected_realm_id': realm_id,\n",
    "                    'has_queue': detail.get('has_queue', False),\n",
    "                    'status_type': detail.get('status', {}).get('type'),\n",
    "                    'population_type': detail.get('population', {}).get('type'),\n",
    "                    'num_realms': len(detail.get('realms', []))\n",
    "                }\n",
    "                \n",
    "                # Get realm names (comma-separated if multiple)\n",
    "                realm_names = [r.get('name', '') for r in detail.get('realms', [])]\n",
    "                realm_info['realm_names'] = ', '.join(realm_names)\n",
    "                \n",
    "                # Get realm slugs\n",
    "                realm_slugs = [r.get('slug', '') for r in detail.get('realms', [])]\n",
    "                realm_info['realm_slugs'] = ', '.join(realm_slugs)\n",
    "                \n",
    "                realm_list.append(realm_info)\n",
    "            else:\n",
    "                realm_list.append({'connected_realm_id': realm_id})\n",
    "            \n",
    "        df = pd.DataFrame(realm_list)\n",
    "        \n",
    "        # Optimize data types\n",
    "        df = self._optimize_realm_dtypes(df)\n",
    "        \n",
    "        # Ensure filename is a Path and save\n",
    "        filepath = self.data_dir / filename if not Path(filename).is_absolute() else Path(filename)\n",
    "        df.to_parquet(filepath, engine='pyarrow', compression=self.compression, index=False)\n",
    "        print(f\"Saved {len(df)} connected realms to {filepath}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def save_multiple_realm_auctions_to_parquet(self, auctions_dict, timestamp_str=None):\n",
    "        \"\"\"\n",
    "        Save auction data for multiple realms to separate Parquet files\n",
    "        \n",
    "        Args:\n",
    "            auctions_dict: Dictionary mapping realm_id to auction data\n",
    "            timestamp_str: Optional timestamp string for filenames\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping realm_id to DataFrame\n",
    "        \"\"\"\n",
    "        if timestamp_str is None:\n",
    "            timestamp_str = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        dataframes = {}\n",
    "        for realm_id, auction_data in auctions_dict.items():\n",
    "            filename = f'auctions_realm_{realm_id}_{timestamp_str}.parquet'\n",
    "            df = self.save_auctions_to_parquet(auction_data, filename, connected_realm_id=realm_id)\n",
    "            if df is not None:\n",
    "                dataframes[realm_id] = df\n",
    "        \n",
    "        return dataframes\n",
    "    \n",
    "    def save_combined_realm_auctions_to_parquet(self, auctions_dict, filename, timestamp_str=None):\n",
    "        \"\"\"\n",
    "        Save auction data for multiple realms to a single Parquet file\n",
    "        \n",
    "        Args:\n",
    "            auctions_dict: Dictionary mapping realm_id to auction data\n",
    "            filename: Output filename\n",
    "            timestamp_str: Optional timestamp string for fetch_timestamp\n",
    "        \n",
    "        Returns:\n",
    "            Combined DataFrame\n",
    "        \"\"\"\n",
    "        all_dfs = []\n",
    "        \n",
    "        for realm_id, auction_data in auctions_dict.items():\n",
    "            auctions = auction_data.get('auctions', [])\n",
    "            if not auctions:\n",
    "                continue\n",
    "            \n",
    "            # Flatten auctions for this realm\n",
    "            flattened = []\n",
    "            timestamp = datetime.utcnow()\n",
    "            \n",
    "            for auction in auctions:\n",
    "                flat_auction = {\n",
    "                    'fetch_timestamp': timestamp,\n",
    "                    'connected_realm_id': realm_id,\n",
    "                    'auction_id': auction.get('id'),\n",
    "                    'item_id': auction.get('item', {}).get('id'),\n",
    "                    'quantity': auction.get('quantity', 1),\n",
    "                    'unit_price': auction.get('unit_price'),\n",
    "                    'buyout': auction.get('buyout'),\n",
    "                    'time_left': auction.get('time_left'),\n",
    "                }\n",
    "                \n",
    "                # Handle item bonuses\n",
    "                item = auction.get('item', {})\n",
    "                if 'bonus_lists' in item:\n",
    "                    flat_auction['bonus_lists'] = ','.join(map(str, item['bonus_lists']))\n",
    "                \n",
    "                if 'bid' in auction:\n",
    "                    flat_auction['bid'] = auction['bid']\n",
    "                \n",
    "                flattened.append(flat_auction)\n",
    "            \n",
    "            df = pd.DataFrame(flattened)\n",
    "            all_dfs.append(df)\n",
    "        \n",
    "        if not all_dfs:\n",
    "            print(\"No auctions to save\")\n",
    "            return None\n",
    "        \n",
    "        # Combine all dataframes\n",
    "        combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined_df = self._optimize_auction_dtypes(combined_df)\n",
    "        \n",
    "        # Save\n",
    "        filepath = self.data_dir / filename if not Path(filename).is_absolute() else Path(filename)\n",
    "        combined_df.to_parquet(filepath, engine='pyarrow', compression=self.compression, index=False)\n",
    "        \n",
    "        file_size = filepath.stat().st_size / (1024 * 1024)\n",
    "        print(f\"Saved {len(combined_df)} total auctions from {len(auctions_dict)} realms to {filepath} ({file_size:.2f} MB)\")\n",
    "        \n",
    "        return combined_df\n",
    "    \n",
    "    def save_to_json(self, data, filename):\n",
    "        \"\"\"Save data to JSON file (for reference/debugging)\"\"\"\n",
    "        filepath = self.data_dir / filename if not Path(filename).is_absolute() else Path(filename)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Data saved to {filepath}\")\n",
    "    \n",
    "    def _optimize_auction_dtypes(self, df):\n",
    "        \"\"\"Optimize data types for auction DataFrames\"\"\"\n",
    "        if 'auction_id' in df.columns:\n",
    "            df['auction_id'] = df['auction_id'].astype('int64')\n",
    "        if 'item_id' in df.columns:\n",
    "            df['item_id'] = df['item_id'].astype('int32')\n",
    "        if 'quantity' in df.columns:\n",
    "            df['quantity'] = df['quantity'].astype('int16')\n",
    "        if 'unit_price' in df.columns:\n",
    "            df['unit_price'] = df['unit_price'].astype('int64')\n",
    "        if 'buyout' in df.columns:\n",
    "            df['buyout'] = df['buyout'].astype('int64')\n",
    "        if 'bid' in df.columns:\n",
    "            df['bid'] = df['bid'].astype('int64')\n",
    "        if 'time_left' in df.columns:\n",
    "            df['time_left'] = df['time_left'].astype('category')\n",
    "        if 'connected_realm_id' in df.columns:\n",
    "            df['connected_realm_id'] = df['connected_realm_id'].astype('int16')\n",
    "        return df\n",
    "    \n",
    "    def _optimize_realm_dtypes(self, df):\n",
    "        \"\"\"Optimize data types for realm DataFrames\"\"\"\n",
    "        if 'connected_realm_id' in df.columns:\n",
    "            df['connected_realm_id'] = df['connected_realm_id'].astype('int16')\n",
    "        if 'has_queue' in df.columns:\n",
    "            df['has_queue'] = df['has_queue'].astype('bool')\n",
    "        if 'status_type' in df.columns:\n",
    "            df['status_type'] = df['status_type'].astype('category')\n",
    "        if 'population_type' in df.columns:\n",
    "            df['population_type'] = df['population_type'].astype('category')\n",
    "        if 'num_realms' in df.columns:\n",
    "            df['num_realms'] = df['num_realms'].astype('int8')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9363fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "\n",
    "writer = ParquetWriter(root_dir=WA_STORAGE_LOCAL_DIR, region=BLIZZARD_API_REGION, compression='snappy')\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    # Use async context manager\n",
    "    async with BlizzardAuctionHouseClient(BLIZZARD_API_CLIENT_ID, BLIZZARD_API_CLIENT_SECRET, BLIZZARD_API_REGION) as client:\n",
    "        \n",
    "        print(\"\\nFetching connected realms...\")\n",
    "        realm_ids = await client.get_connected_realms_index()\n",
    "        print(f\"Found {len(realm_ids)} connected realms\")\n",
    "        realm_details = await client.get_all_realm_details(realm_ids)\n",
    "\n",
    "        # Store connected realms\n",
    "        df_realms = writer.save_connected_realms_to_parquet(\n",
    "            realm_ids, \n",
    "            'connected_realms.parquet',\n",
    "            realm_details=realm_details\n",
    "        )\n",
    "        \n",
    "# Run\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wow-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
